{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56f3c3499260fe04c9d0c6535f59ea3320b8c987",
    "collapsed": true
   },
   "source": [
    "> Please go through Giba's post and kernel  to underrstand what this leak is all about\n",
    "> https://www.kaggle.com/titericz/the-property-by-giba (kernel)\n",
    "> https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61329 (post)\n",
    "> \n",
    "> Also, go through this Jiazhen's kernel which finds more columns to exploit leak\n",
    "> https://www.kaggle.com/johnfarrell/giba-s-property-extended-result\n",
    "> \n",
    "> I just exploit data property in brute force way and then fill in remaining by row non zero means! This should bring everyone on level-playing field.\n",
    "> \n",
    "> **Let the competition begin! :D**\n",
    "\n",
    "### Just some small modifications from [original baseline](https://www.kaggle.com/tezdhar/breaking-lb-fresh-start)~\n",
    "- The leak rows are calculated separately on train/test set\n",
    "- To accelarate the fake rows(maybe) of testset are dropped\n",
    "- Calculated the leaky values, correctness, for each lag\n",
    "- Hope this can help to do some *lag_selection*\n",
    "\n",
    "### (Update) leak process codes to Dmitry Frumkin's *fast* [version](https://www.kaggle.com/dfrumkin/a-simple-way-to-use-giba-s-features-v2)\n",
    "- The result of Dmitry Frumkin's [fast function](https://www.kaggle.com/dfrumkin/a-simple-way-to-use-giba-s-features-v2) and result of [Mohsin Hasan's function](https://www.kaggle.com/tezdhar/breaking-lb-fresh-start) seem slightly different\n",
    "- Modified to make the output consistent with Mohsin Hasan's function (Seems better score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LP Cheung\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import mode, skew, kurtosis, entropy\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "dc37a766646b5993cef0bc87ad6882728dd20cb2"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/origin/'\n",
    "train = pd.read_csv(DATA_DIR+\"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR+\"test.csv\")\n",
    "\n",
    "transact_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]\n",
    "y = np.log1p(train[\"target\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "34577b8d26645eac8ca2cf7df58dc82b581cdc35"
   },
   "outputs": [],
   "source": [
    "def get_beautiful_test(test):\n",
    "    test_rnd = np.round(test.iloc[:, 1:], 2)\n",
    "    ugly_indexes = []\n",
    "    non_ugly_indexes = []\n",
    "    for idx in tqdm(range(len(test))):\n",
    "        if not np.all(\n",
    "            test_rnd.iloc[idx, :].values==test.iloc[idx, 1:].values\n",
    "        ):\n",
    "            ugly_indexes.append(idx)\n",
    "        else:\n",
    "            non_ugly_indexes.append(idx)\n",
    "    print(len(ugly_indexes), len(non_ugly_indexes))\n",
    "    np.save('test_ugly_indexes', np.array(ugly_indexes))\n",
    "    np.save('test_non_ugly_indexes', np.array(non_ugly_indexes))\n",
    "    test = test.iloc[non_ugly_indexes].reset_index(drop=True)\n",
    "    return test, non_ugly_indexes, ugly_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "9951f375af0d5a753031352e04a85a5a12a93e18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 49342/49342 [04:08<00:00, 198.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31792 17550\n"
     ]
    }
   ],
   "source": [
    "test, non_ugly_indexes, ugly_indexes = get_beautiful_test(test)\n",
    "test[\"target\"] = train[\"target\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6dcfc4df1340c38bfeac43fd4d19ba2763b3b916"
   },
   "source": [
    "We take time series columns from [here](https://www.kaggle.com/johnfarrell/giba-s-property-extended-result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect();\n",
    "cols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1', '15ace8c9f', \n",
    "        'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9', 'd6bb78916', 'b43a7cfd5', \n",
    "        '58232a6fb', '1702b5bf0', '324921c7b', '62e59a501', '2ec5b290f', '241f0f867', \n",
    "        'fb49e4212', '66ace2992', 'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', \n",
    "        '1931ccfdd', '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a', \n",
    "        '6619d81fc', '1db387535', \n",
    "        'fc99f9426', '91f701ba2', '0572565c2', '190db8488', 'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d61c75092518f50a879e9e3d5883ab752f73912b"
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "CPU_CORES = 1\n",
    "# from: https://www.kaggle.com/tezdhar/breaking-lb-fresh-start\n",
    "def _get_leak(df, cols, lag=0, verbose=False):\n",
    "    \"\"\" To get leak value, we do following:\n",
    "       1. Get string of all values after removing first two time steps\n",
    "       2. For all rows we shift the row by two steps and again make a string\n",
    "       3. Just find rows where string from 2 matches string from 1\n",
    "       4. Get 1st time step of row in 3 (Currently, there is additional condition to only fetch value if we got exactly one match in step 3)\"\"\"\n",
    "    series_str = df[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n",
    "    series_shifted_str = df[cols].shift(lag+2, axis=1)[cols[lag+2:]].apply(lambda x: \"_\".join(x.round(2).astype(str)), axis=1)\n",
    "    if verbose:\n",
    "        target_rows = series_shifted_str.progress_apply(lambda x: np.where(x == series_str)[0])\n",
    "    else:\n",
    "        target_rows = series_shifted_str.apply(lambda x: np.where(x == series_str)[0])\n",
    "    target_vals = target_rows.apply(lambda x: df.loc[x[0], cols[lag]] if len(x)==1 else 0)\n",
    "    return target_vals\n",
    "\n",
    "# from: https://www.kaggle.com/dfrumkin/a-simple-way-to-use-giba-s-features-v2\n",
    "def fast_get_leak(df, cols, lag=0):\n",
    "    d1 = df[cols[:-lag-2]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2 = df[cols[lag+2:]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2['pred'] = df[cols[lag]]\n",
    "    #d2 = d2[d2.pred != 0] ### to make output consistent with Hasan's function\n",
    "    d3 = d2[~d2.duplicated(['key'], keep=False)]\n",
    "    return d1.merge(d3, how='left', on='key').pred.fillna(0)\n",
    "\n",
    "def compiled_leak_result():\n",
    "    \n",
    "    max_nlags = len(cols) - 2\n",
    "    train_leak = train[[\"ID\", \"target\"] + cols]\n",
    "    train_leak[\"compiled_leak\"] = 0\n",
    "    train_leak[\"nonzero_mean\"] = train[transact_cols].apply(\n",
    "        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    leaky_value_counts = []\n",
    "    leaky_value_corrects = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        \n",
    "        print('Processing lag', i)\n",
    "        train_leak[c] = fast_get_leak(train_leak, cols, i)\n",
    "        \n",
    "        leaky_cols.append(c)\n",
    "        train_leak = train.join(\n",
    "            train_leak.set_index(\"ID\")[leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]], \n",
    "            on=\"ID\", how=\"left\"\n",
    "        )\n",
    "        zeroleak = train_leak[\"compiled_leak\"]==0\n",
    "        train_leak.loc[zeroleak, \"compiled_leak\"] = train_leak.loc[zeroleak, c]\n",
    "        leaky_value_counts.append(sum(train_leak[\"compiled_leak\"] > 0))\n",
    "        _correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n",
    "        leaky_value_corrects.append(_correct_counts/leaky_value_counts[-1])\n",
    "        print(\"Leak values found in train\", leaky_value_counts[-1])\n",
    "        print(\n",
    "            \"% of correct leaks values in train \", \n",
    "            leaky_value_corrects[-1]\n",
    "        )\n",
    "        tmp = train_leak.copy()\n",
    "        tmp.loc[zeroleak, \"compiled_leak\"] = tmp.loc[zeroleak, \"nonzero_mean\"]\n",
    "        scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n",
    "        print(\n",
    "            'Score (filled with nonzero mean)', \n",
    "            scores[-1]\n",
    "        )\n",
    "    result = dict(\n",
    "        score=scores, \n",
    "        leaky_count=leaky_value_counts,\n",
    "        leaky_correct=leaky_value_corrects,\n",
    "    )\n",
    "    return train_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "68f3fde6e5e9d274a4de6ef0975bbb4b682d5e85",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lag 0\n",
      "Leak values found in train 1351\n",
      "% of correct leaks values in train  0.9955588452997779\n",
      "Score (filled with nonzero mean) 1.5138333391635181\n",
      "Processing lag 1\n",
      "Leak values found in train 1947\n",
      "% of correct leaks values in train  0.9964047252182845\n",
      "Score (filled with nonzero mean) 1.2922048129527157\n",
      "Processing lag 2\n",
      "Leak values found in train 2340\n",
      "% of correct leaks values in train  0.9935897435897436\n",
      "Score (filled with nonzero mean) 1.1732829046778301\n",
      "Processing lag 3\n",
      "Leak values found in train 2586\n",
      "% of correct leaks values in train  0.9930394431554525\n",
      "Score (filled with nonzero mean) 1.0843263736726338\n",
      "Processing lag 4\n",
      "Leak values found in train 2754\n",
      "% of correct leaks values in train  0.9934640522875817\n",
      "Score (filled with nonzero mean) 1.0327870440015576\n",
      "Processing lag 5\n",
      "Leak values found in train 2899\n",
      "% of correct leaks values in train  0.9931010693342532\n",
      "Score (filled with nonzero mean) 0.9940324299498773\n",
      "Processing lag 6\n",
      "Leak values found in train 3014\n",
      "% of correct leaks values in train  0.9923689449236894\n",
      "Score (filled with nonzero mean) 0.9475716466467443\n",
      "Processing lag 7\n",
      "Leak values found in train 3110\n",
      "% of correct leaks values in train  0.9919614147909968\n",
      "Score (filled with nonzero mean) 0.9061425741761026\n",
      "Processing lag 8\n",
      "Leak values found in train 3188\n",
      "% of correct leaks values in train  0.9918444165621079\n",
      "Score (filled with nonzero mean) 0.8829375962288961\n",
      "Processing lag 9\n",
      "Leak values found in train 3237\n",
      "% of correct leaks values in train  0.9916589434661723\n",
      "Score (filled with nonzero mean) 0.8645425426899047\n",
      "Processing lag 10\n",
      "Leak values found in train 3296\n",
      "% of correct leaks values in train  0.991504854368932\n",
      "Score (filled with nonzero mean) 0.8514676567599472\n",
      "Processing lag 11\n",
      "Leak values found in train 3336\n",
      "% of correct leaks values in train  0.9916067146282974\n",
      "Score (filled with nonzero mean) 0.8372610483023675\n",
      "Processing lag 12\n",
      "Leak values found in train 3382\n",
      "% of correct leaks values in train  0.9902424600827913\n",
      "Score (filled with nonzero mean) 0.8214331403442912\n",
      "Processing lag 13\n",
      "Leak values found in train 3416\n",
      "% of correct leaks values in train  0.9900468384074942\n",
      "Score (filled with nonzero mean) 0.8154372338396487\n",
      "Processing lag 14\n",
      "Leak values found in train 3450\n",
      "% of correct leaks values in train  0.9901449275362318\n",
      "Score (filled with nonzero mean) 0.8038791462519902\n",
      "Processing lag 15\n",
      "Leak values found in train 3470\n",
      "% of correct leaks values in train  0.9899135446685879\n",
      "Score (filled with nonzero mean) 0.7918901526062936\n",
      "Processing lag 16\n",
      "Leak values found in train 3489\n",
      "% of correct leaks values in train  0.9893952421897392\n",
      "Score (filled with nonzero mean) 0.7909669836528116\n",
      "Processing lag 17\n",
      "Leak values found in train 3511\n",
      "% of correct leaks values in train  0.9894616918256907\n",
      "Score (filled with nonzero mean) 0.7873456935780919\n",
      "Processing lag 18\n",
      "Leak values found in train 3528\n",
      "% of correct leaks values in train  0.9892290249433107\n",
      "Score (filled with nonzero mean) 0.779616215493196\n",
      "Processing lag 19\n",
      "Leak values found in train 3544\n",
      "% of correct leaks values in train  0.9892776523702032\n",
      "Score (filled with nonzero mean) 0.7746425745753253\n",
      "Processing lag 20\n",
      "Leak values found in train 3556\n",
      "% of correct leaks values in train  0.9893138357705287\n",
      "Score (filled with nonzero mean) 0.7687755528095322\n",
      "Processing lag 21\n",
      "Leak values found in train 3573\n",
      "% of correct leaks values in train  0.9882451721242653\n",
      "Score (filled with nonzero mean) 0.7598294446703145\n",
      "Processing lag 22\n",
      "Leak values found in train 3583\n",
      "% of correct leaks values in train  0.9879988836170807\n",
      "Score (filled with nonzero mean) 0.7526327532075343\n",
      "Processing lag 23\n",
      "Leak values found in train 3595\n",
      "% of correct leaks values in train  0.9877607788595271\n",
      "Score (filled with nonzero mean) 0.7497264357981445\n",
      "Processing lag 24\n",
      "Leak values found in train 3605\n",
      "% of correct leaks values in train  0.9869625520110957\n",
      "Score (filled with nonzero mean) 0.7444695955337371\n",
      "Processing lag 25\n",
      "Leak values found in train 3611\n",
      "% of correct leaks values in train  0.98698421489892\n",
      "Score (filled with nonzero mean) 0.7443442780627187\n",
      "Processing lag 26\n",
      "Leak values found in train 3622\n",
      "% of correct leaks values in train  0.9859193815571508\n",
      "Score (filled with nonzero mean) 0.7424266698188008\n",
      "Processing lag 27\n",
      "Leak values found in train 3628\n",
      "% of correct leaks values in train  0.9856670341786108\n",
      "Score (filled with nonzero mean) 0.740890420198593\n",
      "Processing lag 28\n",
      "Leak values found in train 3633\n",
      "% of correct leaks values in train  0.9854115056427195\n",
      "Score (filled with nonzero mean) 0.7376835453405299\n",
      "Processing lag 29\n",
      "Leak values found in train 3637\n",
      "% of correct leaks values in train  0.9846026945284575\n",
      "Score (filled with nonzero mean) 0.7371911838169722\n",
      "Processing lag 30\n",
      "Leak values found in train 3644\n",
      "% of correct leaks values in train  0.9832601536772777\n",
      "Score (filled with nonzero mean) 0.7394311615490367\n",
      "Processing lag 31\n",
      "Leak values found in train 3647\n",
      "% of correct leaks values in train  0.982451329860159\n",
      "Score (filled with nonzero mean) 0.7388315249909507\n",
      "Processing lag 32\n",
      "Leak values found in train 3650\n",
      "% of correct leaks values in train  0.9816438356164383\n",
      "Score (filled with nonzero mean) 0.7393381067031504\n",
      "Processing lag 33\n",
      "Leak values found in train 3660\n",
      "% of correct leaks values in train  0.9795081967213115\n",
      "Score (filled with nonzero mean) 0.7402421029724673\n",
      "Processing lag 34\n",
      "Leak values found in train 3662\n",
      "% of correct leaks values in train  0.9792463134898962\n",
      "Score (filled with nonzero mean) 0.7398911272837491\n",
      "Processing lag 35\n",
      "Leak values found in train 3663\n",
      "% of correct leaks values in train  0.978978978978979\n",
      "Score (filled with nonzero mean) 0.7404147171102294\n",
      "Processing lag 36\n",
      "Leak values found in train 3666\n",
      "% of correct leaks values in train  0.9781778505182761\n",
      "Score (filled with nonzero mean) 0.7432607190143065\n",
      "Processing lag 37\n",
      "Leak values found in train 3666\n",
      "% of correct leaks values in train  0.9781778505182761\n",
      "Score (filled with nonzero mean) 0.7427450896821165\n"
     ]
    }
   ],
   "source": [
    "train_leak, result = compiled_leak_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "8d904afe6c581aa250592432402977b1ab2b3ede"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leaky_correct</th>\n",
       "      <td>0.995559</td>\n",
       "      <td>0.996405</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993039</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.993101</td>\n",
       "      <td>0.992369</td>\n",
       "      <td>0.991961</td>\n",
       "      <td>0.991844</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985412</td>\n",
       "      <td>0.984603</td>\n",
       "      <td>0.983260</td>\n",
       "      <td>0.982451</td>\n",
       "      <td>0.981644</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978979</td>\n",
       "      <td>0.978178</td>\n",
       "      <td>0.978178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaky_count</th>\n",
       "      <td>1351.000000</td>\n",
       "      <td>1947.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2586.000000</td>\n",
       "      <td>2754.000000</td>\n",
       "      <td>2899.000000</td>\n",
       "      <td>3014.000000</td>\n",
       "      <td>3110.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3237.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3633.000000</td>\n",
       "      <td>3637.000000</td>\n",
       "      <td>3644.000000</td>\n",
       "      <td>3647.000000</td>\n",
       "      <td>3650.000000</td>\n",
       "      <td>3660.000000</td>\n",
       "      <td>3662.000000</td>\n",
       "      <td>3663.000000</td>\n",
       "      <td>3666.000000</td>\n",
       "      <td>3666.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.513833</td>\n",
       "      <td>1.292205</td>\n",
       "      <td>1.173283</td>\n",
       "      <td>1.084326</td>\n",
       "      <td>1.032787</td>\n",
       "      <td>0.994032</td>\n",
       "      <td>0.947572</td>\n",
       "      <td>0.906143</td>\n",
       "      <td>0.882938</td>\n",
       "      <td>0.864543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737684</td>\n",
       "      <td>0.737191</td>\n",
       "      <td>0.739431</td>\n",
       "      <td>0.738832</td>\n",
       "      <td>0.739338</td>\n",
       "      <td>0.740242</td>\n",
       "      <td>0.739891</td>\n",
       "      <td>0.740415</td>\n",
       "      <td>0.743261</td>\n",
       "      <td>0.742745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0            1            2            3   \\\n",
       "leaky_correct     0.995559     0.996405     0.993590     0.993039   \n",
       "leaky_count    1351.000000  1947.000000  2340.000000  2586.000000   \n",
       "score             1.513833     1.292205     1.173283     1.084326   \n",
       "\n",
       "                        4            5            6            7   \\\n",
       "leaky_correct     0.993464     0.993101     0.992369     0.991961   \n",
       "leaky_count    2754.000000  2899.000000  3014.000000  3110.000000   \n",
       "score             1.032787     0.994032     0.947572     0.906143   \n",
       "\n",
       "                        8            9      ...                28  \\\n",
       "leaky_correct     0.991844     0.991659     ...          0.985412   \n",
       "leaky_count    3188.000000  3237.000000     ...       3633.000000   \n",
       "score             0.882938     0.864543     ...          0.737684   \n",
       "\n",
       "                        29           30           31           32  \\\n",
       "leaky_correct     0.984603     0.983260     0.982451     0.981644   \n",
       "leaky_count    3637.000000  3644.000000  3647.000000  3650.000000   \n",
       "score             0.737191     0.739431     0.738832     0.739338   \n",
       "\n",
       "                        33           34           35           36           37  \n",
       "leaky_correct     0.979508     0.979246     0.978979     0.978178     0.978178  \n",
       "leaky_count    3660.000000  3662.000000  3663.000000  3666.000000  3666.000000  \n",
       "score             0.740242     0.739891     0.740415     0.743261     0.742745  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame.from_dict(result, orient='columns')\n",
    "result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "629ec0c6ee122fd82bf40f09a55a3f6f8f6c7fdf"
   },
   "outputs": [],
   "source": [
    "result.to_csv('../data/preprocessed/baseline_with_lag_select/train_leaky_stat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "42bfb7c9b41f687c189229f83cc6c8c7fd100536",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>...</th>\n",
       "      <th>leaked_target_30</th>\n",
       "      <th>leaked_target_31</th>\n",
       "      <th>leaked_target_32</th>\n",
       "      <th>leaked_target_33</th>\n",
       "      <th>leaked_target_34</th>\n",
       "      <th>leaked_target_35</th>\n",
       "      <th>leaked_target_36</th>\n",
       "      <th>leaked_target_37</th>\n",
       "      <th>compiled_leak</th>\n",
       "      <th>nonzero_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>2.858973e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>4.303261e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.473861e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>4.017810e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.567102e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5033 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  \\\n",
       "0  000d6aaf2  38000000.0        0.0          0        0.0          0   \n",
       "1  000fbd867    600000.0        0.0          0        0.0          0   \n",
       "2  0027d6b71  10000000.0        0.0          0        0.0          0   \n",
       "3  0028cbf45   2000000.0        0.0          0        0.0          0   \n",
       "4  002a68644  14400000.0        0.0          0        0.0          0   \n",
       "\n",
       "   2f0771a37  30347e683  d08d1fbe3  6ee66e115      ...       leaked_target_30  \\\n",
       "0          0          0          0          0      ...                    0.0   \n",
       "1          0          0          0          0      ...                    0.0   \n",
       "2          0          0          0          0      ...                    0.0   \n",
       "3          0          0          0          0      ...                    0.0   \n",
       "4          0          0          0          0      ...                    0.0   \n",
       "\n",
       "   leaked_target_31  leaked_target_32  leaked_target_33  leaked_target_34  \\\n",
       "0        38000000.0               0.0        38000000.0        38000000.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   leaked_target_35  leaked_target_36  leaked_target_37  compiled_leak  \\\n",
       "0               0.0               0.0               0.0     38000000.0   \n",
       "1               0.0               0.0               0.0       600000.0   \n",
       "2               0.0               0.0               0.0            0.0   \n",
       "3               0.0               0.0               0.0      2000000.0   \n",
       "4               0.0               0.0               0.0            0.0   \n",
       "\n",
       "   nonzero_mean  \n",
       "0  2.858973e+06  \n",
       "1  4.303261e+06  \n",
       "2  2.473861e+06  \n",
       "3  4.017810e+05  \n",
       "4  2.567102e+06  \n",
       "\n",
       "[5 rows x 5033 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_leak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "15e49a1e6f3d95150a4114edca7d3ae910bc6ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score 0.7371911838169722 \n",
      "best_lag 29\n"
     ]
    }
   ],
   "source": [
    "best_score = np.min(result['score'])\n",
    "best_lag = np.argmin(result['score'])\n",
    "print('best_score', best_score, '\\nbest_lag', best_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "9dd516686724d756329a5f42c7c53b688c55aceb"
   },
   "outputs": [],
   "source": [
    "def rewrite_compiled_leak(leak_df, lag):\n",
    "    leak_df[\"compiled_leak\"] = 0\n",
    "    for i in range(lag):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        zeroleak = leak_df[\"compiled_leak\"]==0\n",
    "        leak_df.loc[zeroleak, \"compiled_leak\"] = leak_df.loc[zeroleak, c]\n",
    "    return leak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "c4982c4cd26a0c84ec34402fd7816f49c630e191"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>leaked_target_0</th>\n",
       "      <th>leaked_target_1</th>\n",
       "      <th>leaked_target_2</th>\n",
       "      <th>leaked_target_3</th>\n",
       "      <th>leaked_target_4</th>\n",
       "      <th>leaked_target_5</th>\n",
       "      <th>leaked_target_6</th>\n",
       "      <th>leaked_target_7</th>\n",
       "      <th>leaked_target_8</th>\n",
       "      <th>...</th>\n",
       "      <th>leaked_target_29</th>\n",
       "      <th>leaked_target_30</th>\n",
       "      <th>leaked_target_31</th>\n",
       "      <th>leaked_target_32</th>\n",
       "      <th>leaked_target_33</th>\n",
       "      <th>leaked_target_34</th>\n",
       "      <th>leaked_target_35</th>\n",
       "      <th>leaked_target_36</th>\n",
       "      <th>leaked_target_37</th>\n",
       "      <th>compiled_leak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  leaked_target_0  leaked_target_1  leaked_target_2  \\\n",
       "0  000d6aaf2       38000000.0       38000000.0       38000000.0   \n",
       "1  000fbd867         600000.0              0.0              0.0   \n",
       "2  0027d6b71              0.0              0.0              0.0   \n",
       "3  0028cbf45              0.0              0.0              0.0   \n",
       "4  002a68644              0.0              0.0              0.0   \n",
       "\n",
       "   leaked_target_3  leaked_target_4  leaked_target_5  leaked_target_6  \\\n",
       "0              0.0       38000000.0              0.0       38000000.0   \n",
       "1              0.0              0.0              0.0         600000.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   leaked_target_7  leaked_target_8      ...        leaked_target_29  \\\n",
       "0              0.0              0.0      ...              38000000.0   \n",
       "1              0.0         600000.0      ...                     0.0   \n",
       "2              0.0              0.0      ...                     0.0   \n",
       "3              0.0              0.0      ...                     0.0   \n",
       "4              0.0              0.0      ...                     0.0   \n",
       "\n",
       "   leaked_target_30  leaked_target_31  leaked_target_32  leaked_target_33  \\\n",
       "0               0.0        38000000.0               0.0        38000000.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   leaked_target_34  leaked_target_35  leaked_target_36  leaked_target_37  \\\n",
       "0        38000000.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   compiled_leak  \n",
       "0     38000000.0  \n",
       "1       600000.0  \n",
       "2            0.0  \n",
       "3      2000000.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaky_cols = [c for c in train_leak.columns if 'leaked_target_' in c]\n",
    "train_leak = rewrite_compiled_leak(train_leak, best_lag)\n",
    "train_leak[['ID']+leaky_cols+['compiled_leak']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "a8902d9458668d79eef27c6761a3c6fd43578824"
   },
   "outputs": [],
   "source": [
    "train_res = train_leak[leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "train_res.to_csv('../data/preprocessed/baseline_with_lag_select/train_leak.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = pd.read_csv('../data/preprocessed/baseline_with_lag_select/train_leak.csv')\n",
    "result = pd.read_csv('../data/preprocessed/baseline_with_lag_select/train_leaky_stat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "8ce80d9f0bf6a44471921328a6fd2c274821485d"
   },
   "outputs": [],
   "source": [
    "def compiled_leak_result_test(max_nlags):\n",
    "    test_leak = test[[\"ID\", \"target\"] + cols]\n",
    "    test_leak[\"compiled_leak\"] = 0\n",
    "    test_leak[\"nonzero_mean\"] = test[transact_cols].apply(\n",
    "        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    leaky_value_counts = []\n",
    "    # leaky_value_corrects = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = \"leaked_target_\"+str(i)\n",
    "        \n",
    "        print('Processing lag', i)\n",
    "        test_leak[c] = fast_get_leak(test_leak, cols, i)\n",
    "        \n",
    "        leaky_cols.append(c)\n",
    "        test_leak = test.join(\n",
    "            test_leak.set_index(\"ID\")[leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]], \n",
    "            on=\"ID\", how=\"left\"\n",
    "        )[[\"ID\", \"target\"] + cols + leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]]\n",
    "        zeroleak = test_leak[\"compiled_leak\"]==0\n",
    "        test_leak.loc[zeroleak, \"compiled_leak\"] = test_leak.loc[zeroleak, c]\n",
    "        leaky_value_counts.append(sum(test_leak[\"compiled_leak\"] > 0))\n",
    "        #_correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n",
    "        #leaky_value_corrects.append(_correct_counts/leaky_value_counts[-1])\n",
    "        print(\"Leak values found in test\", leaky_value_counts[-1])\n",
    "        #print(\n",
    "        #    \"% of correct leaks values in train \", \n",
    "        #    leaky_value_corrects[-1]\n",
    "        #)\n",
    "        #tmp = train_leak.copy()\n",
    "        #tmp.loc[zeroleak, \"compiled_leak\"] = tmp.loc[zeroleak, \"nonzero_mean\"]\n",
    "        #scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n",
    "        #print(\n",
    "        #    'Score (filled with nonzero mean)', \n",
    "        #    scores[-1]\n",
    "        #)\n",
    "    result = dict(\n",
    "        # score=scores, \n",
    "        leaky_count=leaky_value_counts,\n",
    "        # leaky_correct=leaky_value_corrects,\n",
    "    )\n",
    "    return test_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "a85699f8864b93664abde5b893426f94583bb7ab",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e4f9606fd3d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_leak\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompiled_leak_result_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_nlags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m38\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-d7e67c8293a4>\u001b[0m in \u001b[0;36mcompiled_leak_result_test\u001b[1;34m(max_nlags)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompiled_leak_result_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_nlags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtest_leak\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest_leak\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"compiled_leak\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     test_leak[\"nonzero_mean\"] = test[transact_cols].apply(\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cols' is not defined"
     ]
    }
   ],
   "source": [
    "test_leak, test_result = compiled_leak_result_test(max_nlags=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f581e7e9f6a68169f2897e44ba9e8919ac6241c6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result = pd.DataFrame.from_dict(test_result, orient='columns')\n",
    "test_result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3559543eccb2c35ae6f06a842f67f9aa54fa264d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result.to_csv('test_leaky_stat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06015b64764b4998669bb7fef877bb781b3ebc1a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_leak = rewrite_compiled_leak(test_leak, best_lag)\n",
    "test_leak[['ID']+leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebca69ea7200a5245e8feeab4cb0b20a2606fb27",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_res = test_leak[leaky_cols+['compiled_leak']].replace(0.0, np.nan)\n",
    "test_res.to_csv('test_leak.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "877d2d1e707082592f5111c7728a7771fdb2d043",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_leak.loc[test_leak[\"compiled_leak\"]==0, \"compiled_leak\"] = test_leak.loc[test_leak[\"compiled_leak\"]==0, \"nonzero_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc2e522df90f97456e67f26977fde364acf02876",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "# sub = test[[\"ID\"]]\n",
    "sub = pd.read_csv(DATA_DIR+\"test.csv\", usecols=[\"ID\"])\n",
    "sub[\"target\"] = 0\n",
    "sub.iloc[non_ugly_indexes, 1] = test_leak[\"compiled_leak\"].values\n",
    "sub.to_csv(f\"non_fake_sub_lag_{best_lag}.csv\", index=False)\n",
    "print(f\"non_fake_sub_lag_{best_lag}.csv saved\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
